{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\whdgh\\Desktop\\projects\\Langchain_Embedding\\.venv\\lib\\site-packages\\deepeval\\__init__.py:42: UserWarning: You are using deepeval version 0.21.47, however version 0.21.48 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n",
      "c:\\Users\\whdgh\\Desktop\\projects\\Langchain_Embedding\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\whdgh\\Desktop\\projects\\Langchain_Embedding\\.venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat ran up the tree."
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import statistics\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = config['API']['OPENAI_API_KEY']\n",
    "\n",
    "from deepeval.metrics import *\n",
    "from deepeval.test_case import *\n",
    "\n",
    "from deepeval.benchmarks import *\n",
    "from deepeval.benchmarks.tasks import *\n",
    "\n",
    "from langchain_community.llms import GPT4All\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "input = \"The dog chased the cat up the tree, who ran up the tree?\"\n",
    "expected_output = \"cat.\"\n",
    "local_path = './models/nous-hermes-llama2-13b.Q4_0.gguf'\n",
    "\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    verbose=True,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    temperature=0.7,\n",
    ")\n",
    "llm_chain = (                     \n",
    "    PromptTemplate(input_variables=[\"question\"], template=input)\n",
    "    | model \n",
    "    | StrOutputParser()\n",
    ")\n",
    "actual_output = llm_chain.invoke({\"question\": \"\"})\n",
    "\n",
    "# model = GPT4All(\n",
    "#     model=local_path,\n",
    "#     # callbacks=[ChainStreamHandler(g)],\n",
    "#     streaming=True,\n",
    "#     verbose=True,\n",
    "# )\n",
    "# llm_chain = PromptTemplate(input_variables=[\"text\"], template=input) | model\n",
    "# actual_output = llm_chain.invoke({\"text\": \"\"})\n",
    "# _res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'input': 'Let x = 1. What is x << 3 in Python 3?\\nA. 1\\nB. 3\\nC. 8\\nD. 16\\nAnswer:',\n",
       "   'expected_output': 'C'},\n",
       "  {'input': 'In Python 3, which of the following function convert a string to an int in python?\\nA. int(x [,base])\\nB. long(x [,base] )\\nC. float(x)\\nD. str(x)\\nAnswer:',\n",
       "   'expected_output': 'A'},\n",
       "  {'input': \"A user enters a Web address in a browser, and a request for a file is sent to a Web server. Which of the following best describes how the file is sent to the user?\\nA. The file is broken into packets for transmission. The packets must be reassembled upon receipt.\\nB. The file is broken into packets for transmission. The user's browser must request each packet in order until all packets are received.\\nC. The server attempts to connect directly to the user's computer. If the connection is successful, the entire file is sent. If the connection is unsuccessful, an error message is sent to the user.\\nD. The server repeatedly attempts to connect directly to the user's computer until a connection is made. Once the connection is made, the entire file is sent.\\nAnswer:\",\n",
       "   'expected_output': 'A'}],\n",
       " 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmlu_benchmark = MMLU().load_benchmark_dataset(MMLUTask.HIGH_SCHOOL_COMPUTER_SCIENCE)\n",
    "data = [{'input': mmlu.input, 'expected_output': mmlu.expected_output} for mmlu in mmlu_benchmark]\n",
    "data[:3], len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = [\n",
    "    'APPLYING_SUNSCREEN',\n",
    "    'TRIMMING_BRANCHES_OR_HEDGES',\n",
    "    'DISC_DOG',\n",
    "    'WAKEBOARDING',\n",
    "    'SKATEBOARDING',\n",
    "    'WATERSKIING',\n",
    "    'WASHING_HANDS',\n",
    "    'SAILING',\n",
    "    'PLAYING_CONGAS',\n",
    "    'BALLET',\n",
    "    'ROOF_SHINGLE_REMOVAL',\n",
    "    'HAND_CAR_WASH',\n",
    "    'KITE_FLYING',\n",
    "    'PLAYING_POOL',\n",
    "    'PLAYING_LACROSSE',\n",
    "    'LAYUP_DRILL_IN_BASKETBALL',\n",
    "    'HOME_AND_GARDEN',\n",
    "    'PLAYING_BEACH_VOLLEYBALL',\n",
    "    'CALF_ROPING',\n",
    "    'SCUBA_DIVING',\n",
    "    'MIXING_DRINKS',\n",
    "    'PUTTING_ON_SHOES',\n",
    "    'MAKING_A_LEMONADE',\n",
    "    'UNCATEGORIZED',\n",
    "    'ZUMBA',\n",
    "    'PLAYING_BADMINTON',\n",
    "    'PLAYING_BAGPIPES',\n",
    "    'FOOD_AND_ENTERTAINING',\n",
    "    'PERSONAL_CARE_AND_STYLE',\n",
    "    'CRICKET',\n",
    "    'SHOVELING_SNOW',\n",
    "    'PING_PONG',\n",
    "    'HOLIDAYS_AND_TRADITIONS',\n",
    "    'ICE_FISHING',\n",
    "    'BEACH_SOCCER',\n",
    "    'TABLE_SOCCER',\n",
    "    'SWIMMING',\n",
    "    'BATON_TWIRLING',\n",
    "    'JAVELIN_THROW',\n",
    "    'SHOT_PUT',\n",
    "    'DOING_CRUNCHES',\n",
    "    'POLISHING_SHOES',\n",
    "    'TRAVEL',\n",
    "    'USING_UNEVEN_BARS',\n",
    "    'PLAYING_HARMONICA',\n",
    "    'RELATIONSHIPS',\n",
    "    'HIGH_JUMP',\n",
    "    'MAKING_A_SANDWICH',\n",
    "    'POWERBOCKING',\n",
    "    'REMOVING_ICE_FROM_CAR',\n",
    "    'SHAVING',\n",
    "    'SHARPENING_KNIVES',\n",
    "    'WELDING',\n",
    "    'USING_PARALLEL_BARS',\n",
    "    'HOME_CATEGORIES',\n",
    "    'ROCK_CLIMBING',\n",
    "    'SNOW_TUBING',\n",
    "    'WASHING_FACE',\n",
    "    'ASSEMBLING_BICYCLE',\n",
    "    'TENNIS_SERVE_WITH_BALL_BOUNCING',\n",
    "    'SHUFFLEBOARD',\n",
    "    'DODGEBALL',\n",
    "    'CAPOEIRA',\n",
    "    'PAINTBALL',\n",
    "    'DOING_A_POWERBOMB',\n",
    "    'DOING_MOTOCROSS',\n",
    "    'PLAYING_ICE_HOCKEY',\n",
    "    'PHILOSOPHY_AND_RELIGION',\n",
    "    'ARCHERY',\n",
    "    'CARS_AND_OTHER_VEHICLES',\n",
    "    'RUNNING_A_MARATHON',\n",
    "    'THROWING_DARTS',\n",
    "    'PAINTING_FURNITURE',\n",
    "    'HAVING_AN_ICE_CREAM',\n",
    "    'SLACKLINING',\n",
    "    'CAMEL_RIDE',\n",
    "    'ARM_WRESTLING',\n",
    "    'HULA_HOOP',\n",
    "    'SURFING',\n",
    "    'PLAYING_PIANO',\n",
    "    'GARGLING_MOUTHWASH',\n",
    "    'PLAYING_ACCORDION',\n",
    "    'HORSEBACK_RIDING',\n",
    "    'PUTTING_IN_CONTACT_LENSES',\n",
    "    'PLAYING_SAXOPHONE',\n",
    "    'FUTSAL',\n",
    "    'LONG_JUMP',\n",
    "    'LONGBOARDING',\n",
    "    'POLE_VAULT',\n",
    "    'BUILDING_SANDCASTLES',\n",
    "    'PLATFORM_DIVING',\n",
    "    'PAINTING',\n",
    "    'SPINNING',\n",
    "    'CARVING_JACK_O_LANTERNS',\n",
    "    'BRAIDING_HAIR',\n",
    "    'YOUTH',\n",
    "    'PLAYING_VIOLIN',\n",
    "    'CANOEING',\n",
    "    'CHEERLEADING',\n",
    "    'PETS_AND_ANIMALS',\n",
    "    'KAYAKING',\n",
    "    'CLEANING_SHOES',\n",
    "    'KNITTING',\n",
    "    'BAKING_COOKIES',\n",
    "    'DOING_FENCING',\n",
    "    'PLAYING_GUITARRA',\n",
    "    'USING_THE_ROWING_MACHINE',\n",
    "    'GETTING_A_HAIRCUT',\n",
    "    'MOOPING_FLOOR',\n",
    "    'RIVER_TUBING',\n",
    "    'CLEANING_SINK',\n",
    "    'GROOMING_DOG',\n",
    "    'DISCUS_THROW',\n",
    "    'CLEANING_WINDOWS',\n",
    "    'FINANCE_AND_BUSINESS',\n",
    "    'HANGING_WALLPAPER',\n",
    "    'ROPE_SKIPPING',\n",
    "    'WINDSURFING',\n",
    "    'KNEELING',\n",
    "    'GETTING_A_PIERCING',\n",
    "    'ROCK_PAPER_SCISSORS',\n",
    "    'SPORTS_AND_FITNESS',\n",
    "    'BREAKDANCING',\n",
    "    'WALKING_THE_DOG',\n",
    "    'PLAYING_DRUMS',\n",
    "    'PLAYING_WATER_POLO',\n",
    "    'BMX',\n",
    "    'SMOKING_A_CIGARETTE',\n",
    "    'BLOWING_LEAVES',\n",
    "    'BULLFIGHTING',\n",
    "    'DRINKING_COFFEE',\n",
    "    'BATHING_DOG',\n",
    "    'TANGO',\n",
    "    'WRAPPING_PRESENTS',\n",
    "    'PLASTERING',\n",
    "    'PLAYING_BLACKJACK',\n",
    "    'FUN_SLIDING_DOWN',\n",
    "    'WORK_WORLD',\n",
    "    'TRIPLE_JUMP',\n",
    "    'TUMBLING',\n",
    "    'SKIING',\n",
    "    'DOING_KICKBOXING',\n",
    "    'BLOW_DRYING_HAIR',\n",
    "    'DRUM_CORPS',\n",
    "    'SMOKING_HOOKAH',\n",
    "    'MOWING_THE_LAWN',\n",
    "    'VOLLEYBALL',\n",
    "    'LAYING_TILE',\n",
    "    'STARTING_A_CAMPFIRE',\n",
    "    'SUMO',\n",
    "    'HURLING',\n",
    "    'PLAYING_KICKBALL',\n",
    "    'MAKING_A_CAKE',\n",
    "    'FIXING_THE_ROOF',\n",
    "    'PLAYING_POLO',\n",
    "    'REMOVING_CURLERS',\n",
    "    'ELLIPTICAL_TRAINER',\n",
    "    'HEALTH',\n",
    "    'SPREAD_MULCH',\n",
    "    'CHOPPING_WOOD',\n",
    "    'BRUSHING_TEETH',\n",
    "    'USING_THE_POMMEL_HORSE',\n",
    "    'SNATCH',\n",
    "    'CLIPPING_CAT_CLAWS',\n",
    "    'PUTTING_ON_MAKEUP',\n",
    "    'HAND_WASHING_CLOTHES',\n",
    "    'HITTING_A_PINATA',\n",
    "    'TAI_CHI',\n",
    "    'GETTING_A_TATTOO',\n",
    "    'DRINKING_BEER',\n",
    "    'SHAVING_LEGS',\n",
    "    'DOING_KARATE',\n",
    "    'PLAYING_RUBIK_CUBE',\n",
    "    'FAMILY_LIFE',\n",
    "    'ROLLERBLADING',\n",
    "    'EDUCATION_AND_COMMUNICATIONS',\n",
    "    'FIXING_BICYCLE',\n",
    "    'BEER_PONG',\n",
    "    'IRONING_CLOTHES',\n",
    "    'CUTTING_THE_GRASS',\n",
    "    'RAKING_LEAVES',\n",
    "    'PLAYING_SQUASH',\n",
    "    'HOPSCOTCH',\n",
    "    'INSTALLING_CARPET',\n",
    "    'POLISHING_FURNITURE',\n",
    "    'DECORATING_THE_CHRISTMAS_TREE',\n",
    "    'PREPARING_SALAD',\n",
    "    'PREPARING_PASTA',\n",
    "    'VACUUMING_FLOOR',\n",
    "    'CLEAN_AND_JERK',\n",
    "    'COMPUTERS_AND_ELECTRONICS',\n",
    "    'CROQUET'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54218.35 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 50195.51 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55186.19 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55788.79 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 57056.78 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55481.98 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53989.28 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56734.91 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 57041.33 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54562.72 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53976.97 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55568.87 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54080.30 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56100.44 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54268.58 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 50963.39 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 51234.42 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53916.92 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55482.56 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54282.57 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55480.30 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 37894.36 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55461.16 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54887.02 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52031.20 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53416.19 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55775.05 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52852.68 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54581.53 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54681.09 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56736.05 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56508.08 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54000.08 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55590.94 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54875.43 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54037.01 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54801.61 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55107.27 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56114.49 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56114.34 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54936.85 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55775.94 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52078.48 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55327.26 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54901.11 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53688.27 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55481.32 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54575.66 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55775.35 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54047.27 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 47828.70 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 47379.51 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54266.48 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55480.74 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 50608.29 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56087.37 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54564.98 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53420.73 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53986.86 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 51721.89 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 38187.32 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55162.84 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54576.22 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54872.29 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52576.45 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53414.29 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55466.78 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52575.85 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55493.09 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52864.36 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55688.04 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55176.06 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55685.97 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53122.86 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54874.43 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55189.22 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55483.30 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56226.03 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54901.97 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54561.66 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55791.23 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56027.46 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56415.81 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55188.93 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55176.21 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 51969.95 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55475.62 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53608.19 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55085.86 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54293.13 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53977.11 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52853.48 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53712.78 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55795.74 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54604.38 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54576.65 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56100.29 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53853.57 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54874.22 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54275.15 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55493.90 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54470.42 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54265.50 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54575.30 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55175.92 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54576.37 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 51967.70 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55480.52 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 38038.82 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53148.33 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55176.06 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52031.32 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54591.08 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 51749.53 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53996.34 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 50208.73 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53245.69 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52196.46 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54292.43 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53427.98 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55161.90 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55169.63 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55486.58 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55467.44 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54955.27 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54280.82 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55802.17 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56085.72 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54280.47 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54281.52 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54575.94 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55163.27 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54575.80 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 49476.97 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54572.33 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54885.66 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53996.48 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54280.47 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55481.83 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55178.67 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55480.74 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55467.00 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54874.00 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52032.55 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55454.44 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56100.29 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53415.51 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56100.66 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 50945.63 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54267.46 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52289.84 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 51107.47 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 49467.32 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56416.87 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 50974.43 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 50477.22 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55163.42 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55776.09 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 36258.36 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54560.74 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54281.52 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53988.87 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 51219.34 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53401.97 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52024.13 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55082.33 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52760.06 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54280.54 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 41270.96 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54907.41 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54285.44 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52812.19 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54576.86 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54876.44 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54875.43 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52853.48 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 50285.10 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54285.16 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54860.85 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54575.94 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56101.26 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54576.15 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54281.31 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54575.73 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54275.08 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 51292.32 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 50198.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_list = []\n",
    "for idx, b in enumerate(benchmarks):\n",
    "    data_list += HellaSwag().load_benchmark_dataset(HellaSwagTask[b])\n",
    "\n",
    "data = [{'input': obj.input, 'expected_output': obj.expected_output} for obj in data_list]\n",
    "pd.DataFrame(data).to_csv('HellaSwagData.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [HellaSwag().load_benchmark_dataset(HellaSwagTask.TRIMMING_BRANCHES_OR_HEDGES), HellaSwag().load_benchmark_dataset(HellaSwagTask.BATON_TWIRLING)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'input': 'A man is shown working in an outdoor garden. he\\nA. is using tools as he works.\\nB. uses a large tool to bark out a few new leaves.\\nC. uses trowels and strikes a tree.\\nD. uses a sponge and a trowel to scrub down the side of a tree.\\nAnswer:',\n",
       "   'expected_output': 'A'},\n",
       "  {'input': 'A man is standing outside turning on his hedge trimmer turning it around to make the blades go. He then walks over to the hedges and begins to cut down the leaves on it. as he\\nA. cuts it asia walks towards the lawn.\\nB. is cutting by himself, a car drives by that is parked over in the yard.\\nC. is cutting it, he begins to walk into the hedges to cut the hedge evenly and shaking the cut leaves off with his hand.\\nD. is doing his mowing he trips and falls down.\\nAnswer:',\n",
       "   'expected_output': 'C'},\n",
       "  {'input': 'A man has climbed a large ladder outside. he\\nA. is using trimmers to cut and trim large trees.\\nB. ropes and lures a cow into the open.\\nC. is using it to pull himself up onto a platform where a car is parked.\\nD. is life saving at the bottom of the ladder.\\nAnswer:',\n",
       "   'expected_output': 'A'}],\n",
       " 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define benchmark with specific tasks and shots\n",
    "# benchmark = MMLU()\n",
    "hella_benchmark = HellaSwag().load_benchmark_dataset(HellaSwagTask.TRIMMING_BRANCHES_OR_HEDGES)\n",
    "data = [{'input': hella.input, 'expected_output': hella.expected_output} for hella in hella_benchmark]\n",
    "data[:3], len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TruthfulQA.load_benchmark_dataset() missing 1 required positional argument: 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mTruthfulQA\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_benchmark_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTruthfulQATask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mADVERTISING\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: TruthfulQA.load_benchmark_dataset() missing 1 required positional argument: 'mode'"
     ]
    }
   ],
   "source": [
    "TruthfulQA().load_benchmark_dataset(TruthfulQATask.ADVERTISING, TruthfulQAMode.MC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hella_benchmark = TruthfulQA().load_benchmark_dataset(TruthfulQATask.TRIMMING_BRANCHES_OR_HEDGES)\n",
    "data = [{'input': hella.input, 'expected_output': hella.expected_output} for hella in hella_benchmark]\n",
    "data[:3], len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A. is using tools as he works."
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\whdgh\\Desktop\\projects\\Langchain_Embedding\\.venv\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\whdgh\\Desktop\\projects\\Langchain_Embedding\\.venv\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\whdgh\\Desktop\\projects\\Langchain_Embedding\\.venv\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\whdgh\\Desktop\\projects\\Langchain_Embedding\\.venv\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'metric_score': 1.0,\n",
       "  'metric_reason': 'The actual output directly indicates the correct expected output answer A, confirming he is using tools as he works.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = GEval(\n",
    "    name=\"Correctness\",\n",
    "    criteria=\"Determine whether the actual output is factually correct based on the expected output.\",\n",
    "    # NOTE: you can only provide either criteria or evaluation_steps, and not both\n",
    "    evaluation_steps=[\n",
    "        \"Check whether the facts in 'actual output' indicates the given 'expected output'\",\n",
    "        \"It does not matter whether the 'actual output' has full context or not.\",\n",
    "        \"If indicating to correct 'expected output' answer must be OK\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    ") \n",
    "\n",
    "benchmark = HumanEval(\n",
    "    tasks=[HumanEvalTask.HAS_CLOSE_ELEMENTS, HumanEvalTask.SORT_NUMBERS],\n",
    "    n=100\n",
    ")\n",
    "\n",
    "metric = HallucinationMetric(threshold=0.5)\n",
    "\n",
    "template = \"\"\"\n",
    "    You are a wise and precise chatbot.\n",
    "    With the below given questions, you will have to solve the question and answer the question instructed with several options to select\n",
    "    {question}\n",
    "    Provide only the letter corresponding to your answer (e.g., \"A\", \"B\", \"C\", etc.).\n",
    "\"\"\"\n",
    "\n",
    "llm_chain = (                     \n",
    "    PromptTemplate(input_variables=[\"question\"], template=template)\n",
    "    | model \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "test_result = []\n",
    "for evaluate in data:\n",
    "    # actual_output = llm_chain.invoke({\"question\": \"It depends, some might consider the cat, while others might argue the dog.\"})\n",
    "    actual_output = llm_chain.invoke({\"question\": evaluate['input']})\n",
    "    # actual_output = \"A\"\n",
    "\n",
    "    test_case = LLMTestCase(\n",
    "        input=evaluate['input'],\n",
    "        actual_output=actual_output,\n",
    "        expected_output=evaluate['expected_output']\n",
    "    )\n",
    "\n",
    "    metric.measure(test_case)\n",
    "    result = {'metric_score' : metric.score, 'metric_reason': metric.reason}\n",
    "    test_result.append(result)\n",
    "    break\n",
    "\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델: ChatOpenAI\n",
      "GEval 평가 평균: 1.0\n"
     ]
    }
   ],
   "source": [
    "len(test_result), test_result\n",
    "avg = statistics.mean([eval['metric_score'] for eval in test_result])\n",
    "print(f\"모델: ChatOpenAI\\nGEval 평가 평균: {avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_score</th>\n",
       "      <th>metric_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>The actual output directly indicates the corre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   metric_score                                      metric_reason\n",
       "0           1.0  The actual output directly indicates the corre..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(test_result).to_csv('result.csv', encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
