{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208522, 35030)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [\n",
    "    \"Accounting-train\", \"Accounting-dev\", \"Accounting-test\",\n",
    "    \"Agricultural-Sciences-train\", \"Agricultural-Sciences-dev\", \"Agricultural-Sciences-test\",\n",
    "    \"Aviation-Engineering-and-Maintenance-train\", \"Aviation-Engineering-and-Maintenance-dev\", \"Aviation-Engineering-and-Maintenance-test\",\n",
    "    \"Biology-train\", \"Biology-dev\", \"Biology-test\",\n",
    "    \"Chemical-Engineering-train\", \"Chemical-Engineering-dev\", \"Chemical-Engineering-test\",\n",
    "    \"Chemistry-train\", \"Chemistry-dev\", \"Chemistry-test\",\n",
    "    \"Civil-Engineering-train\", \"Civil-Engineering-dev\", \"Civil-Engineering-test\",\n",
    "    \"Computer-Science-train\", \"Computer-Science-dev\", \"Computer-Science-test\",\n",
    "    \"Construction-train\", \"Construction-dev\", \"Construction-test\",\n",
    "    \"Criminal-Law-train\", \"Criminal-Law-dev\", \"Criminal-Law-test\",\n",
    "    \"Ecology-train\", \"Ecology-dev\", \"Ecology-test\",\n",
    "    \"Economics-train\", \"Economics-dev\", \"Economics-test\",\n",
    "    \"Education-train\", \"Education-dev\", \"Education-test\",\n",
    "    \"Electrical-Engineering-train\", \"Electrical-Engineering-dev\", \"Electrical-Engineering-test\",\n",
    "    \"Electronics-Engineering-train\", \"Electronics-Engineering-dev\", \"Electronics-Engineering-test\",\n",
    "    \"Energy-Management-train\", \"Energy-Management-dev\", \"Energy-Management-test\",\n",
    "    \"Environmental-Science-train\", \"Environmental-Science-dev\", \"Environmental-Science-test\",\n",
    "    \"Fashion-train\", \"Fashion-dev\", \"Fashion-test\",\n",
    "    \"Food-Processing-train\", \"Food-Processing-dev\", \"Food-Processing-test\",\n",
    "    \"Gas-Technology-and-Engineering-train\", \"Gas-Technology-and-Engineering-dev\", \"Gas-Technology-and-Engineering-test\",\n",
    "    \"Geomatics-train\", \"Geomatics-dev\", \"Geomatics-test\",\n",
    "    \"Health-train\", \"Health-dev\", \"Health-test\",\n",
    "    \"Industrial-Engineer-train\", \"Industrial-Engineer-dev\", \"Industrial-Engineer-test\",\n",
    "    \"Information-Technology-train\", \"Information-Technology-dev\", \"Information-Technology-test\",\n",
    "    \"Interior-Architecture-and-Design-train\", \"Interior-Architecture-and-Design-dev\", \"Interior-Architecture-and-Design-test\",\n",
    "    \"Law-train\", \"Law-dev\", \"Law-test\",\n",
    "    \"Machine-Design-and-Manufacturing-train\", \"Machine-Design-and-Manufacturing-dev\", \"Machine-Design-and-Manufacturing-test\",\n",
    "    \"Management-train\", \"Management-dev\", \"Management-test\",\n",
    "    \"Maritime-Engineering-train\", \"Maritime-Engineering-dev\", \"Maritime-Engineering-test\",\n",
    "    \"Marketing-train\", \"Marketing-dev\", \"Marketing-test\",\n",
    "    \"Materials-Engineering-train\", \"Materials-Engineering-dev\", \"Materials-Engineering-test\",\n",
    "    \"Mechanical-Engineering-train\", \"Mechanical-Engineering-dev\", \"Mechanical-Engineering-test\",\n",
    "    \"Nondestructive-Testing-train\", \"Nondestructive-Testing-dev\", \"Nondestructive-Testing-test\",\n",
    "    \"Patent-train\", \"Patent-dev\", \"Patent-test\",\n",
    "    \"Political-Science-and-Sociology-train\", \"Political-Science-and-Sociology-dev\", \"Political-Science-and-Sociology-test\",\n",
    "    \"Psychology-train\", \"Psychology-dev\", \"Psychology-test\",\n",
    "    \"Public-Safety-train\", \"Public-Safety-dev\", \"Public-Safety-test\",\n",
    "    \"Railway-and-Automotive-Engineering-train\", \"Railway-and-Automotive-Engineering-dev\", \"Railway-and-Automotive-Engineering-test\",\n",
    "    \"Real-Estate-train\", \"Real-Estate-dev\", \"Real-Estate-test\",\n",
    "    \"Refrigerating-Machinery-train\", \"Refrigerating-Machinery-dev\", \"Refrigerating-Machinery-test\",\n",
    "    \"Social-Welfare-train\", \"Social-Welfare-dev\", \"Social-Welfare-test\",\n",
    "    \"Taxation-train\", \"Taxation-dev\", \"Taxation-test\",\n",
    "    \"Telecommunications-and-Wireless-Technology-train\", \"Telecommunications-and-Wireless-Technology-dev\", \"Telecommunications-and-Wireless-Technology-test\",\n",
    "    \"korean-history-train\", \"korean-history-dev\", \"korean-history-test\",\n",
    "    \"math-train\", \"math-dev\", \"math-test\"\n",
    "]\n",
    "\n",
    "DATA = [f\"data/{d}.csv\" for d in data]\n",
    "# splits = {'train': 'data/Accounting-train.csv', 'dev': 'data/Accounting-dev.csv', 'test': 'data/Accounting-test.csv'}\n",
    "train_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "for d in DATA:\n",
    "    if d.endswith('train.csv'):\n",
    "        tmp = pd.read_csv(f\"hf://datasets/HAERAE-HUB/KMMLU/{d}\")\n",
    "        train_df = pd.concat([train_df, tmp], axis=0)\n",
    "    elif d.endswith('test.csv'):\n",
    "        tmp = pd.read_csv(f\"hf://datasets/HAERAE-HUB/KMMLU/{d}\")\n",
    "        test_df = pd.concat([test_df, tmp], axis=0)\n",
    "\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dacac0ec2279467e8e9acec8f4f5b2be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 1\n",
      "reason The score is 1.00 because there were no contradictions found between the actual output and the retrieval context, indicating a perfect alignment.\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import statistics\n",
    "import os\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "os.environ[\"OPENAI_API_KEY\"] = config['API']['OPENAI_API_KEY']\n",
    "\n",
    "from deepeval import evaluate\n",
    "from deepeval.metrics import FaithfulnessMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "# Replace this with the actual output from your LLM application\n",
    "actual_output = \"C\"\n",
    "\n",
    "# Replace this with the actual retrieved context from your RAG pipeline\n",
    "retrieval_context = [\"A, B, C는 맞고 D가 틀리다. 파견근무 대상은 임원 외에도 일반직원이 포함된다\"]\n",
    "\n",
    "metric = FaithfulnessMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4\",\n",
    "    include_reason=True\n",
    ")\n",
    "test_case = LLMTestCase(\n",
    "    input=\"Is the answer correct?\",\n",
    "    actual_output=actual_output,\n",
    "    retrieval_context=retrieval_context\n",
    ")\n",
    "\n",
    "metric.measure(test_case)\n",
    "print(\"score\", metric.score)\n",
    "print(\"reason\", metric.reason)\n",
    "# or evaluate test cases in bulk\n",
    "# evaluate([test_case], [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test test\n"
     ]
    }
   ],
   "source": [
    "from deepeval.benchmarks import HumanEval\n",
    "from deepeval.benchmarks.tasks import HumanEvalTask\n",
    "\n",
    "# Define benchmark with specific tasks and number of code generations\n",
    "benchmark = HumanEval(\n",
    "    tasks=[HumanEvalTask.HAS_CLOSE_ELEMENTS, HumanEvalTask.SORT_NUMBERS],\n",
    "    n=100\n",
    ")\n",
    "\n",
    "# Replace 'gpt_4' with your own custom model\n",
    "benchmark.evaluate(model=gpt_4, k=10)\n",
    "print(benchmark.overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = [\n",
    "{\n",
    "      \"문제\": \"윤영은 누구의 생일 선물을 샀나요?\",\n",
    "      \"CONTEXT\": \"윤영은 상점에서 생일 선물을 사기 위해 왔습니다. 그녀는 동생을 위해 장난감 자동차를 골랐습니다.\",\n",
    "      \"ANSWER\": \"윤영은 자신의 동생을 위해 생일 선물로 장난감 자동차를 샀습니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"지훈이 아침에 학교에 갈 때 탔던 교통수단은 무엇인가요?\",\n",
    "      \"CONTEXT\": \"지훈은 아침에 버스를 타고 학교에 갔습니다. 학교가 끝난 후에는 친구와 함께 지하철을 타고 집에 돌아왔습니다.\",\n",
    "      \"ANSWER\": \"지훈이 아침에 학교에 갈 때 탔던 교통수단은 버스입니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"민지가 학교에서 가장 좋아하는 과목은 무엇인가요?\",\n",
    "      \"CONTEXT\": \"민지는 학교에서 과학, 수학, 역사 과목을 듣고 있습니다. 그 중에서 그녀는 과학을 가장 좋아합니다.\",\n",
    "      \"ANSWER\": \"민지가 학교에서 가장 좋아하는 과목은 과학입니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"수현이가 점심시간에 학교 식당에서 먹은 음식은 무엇인가요?\",\n",
    "      \"CONTEXT\": \"수현이는 점심시간에 학교 식당에서 김밥을 사서 먹었습니다. 친구들은 햄버거와 피자를 먹었습니다.\",\n",
    "      \"ANSWER\": \"수현이가 점심시간에 학교 식당에서 먹은 음식은 김밥입니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"현우가 도서관에서 찾고 있는 책의 제목은 무엇인가요?\",\n",
    "      \"CONTEXT\": \"현우는 도서관에서 '해리 포터' 시리즈를 찾고 있습니다. 그는 최근에 '해리 포터와 마법사의 돌'을 읽기 시작했습니다.\",\n",
    "      \"ANSWER\": \"현우가 도서관에서 찾고 있는 책의 제목은 '해리 포터와 마법사의 돌'입니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"지민이 여름 방학 동안 방문한 도시는 어디인가요?\",\n",
    "      \"CONTEXT\": \"지민은 여름 방학 동안 부산을 방문했습니다. 그는 해운대 해수욕장에서 시간을 보냈습니다.\",\n",
    "      \"ANSWER\": \"지민이 여름 방학 동안 방문한 도시는 부산입니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"수연이 가장 좋아하는 취미는 무엇인가요?\",\n",
    "      \"CONTEXT\": \"수연이는 여러 가지 취미를 가지고 있습니다. 그녀는 특히 그림 그리기를 좋아합니다. 주말마다 미술 학원에 다니며, 시간이 날 때마다 그림을 그립니다.\",\n",
    "      \"ANSWER\": \"수연이 가장 좋아하는 취미는 그림 그리기입니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"지호가 지난 주말에 친구들과 함께 한 활동은 무엇인가요?\",\n",
    "      \"CONTEXT\": \"지호는 지난 주말에 친구들과 함께 영화를 보러 갔습니다. 그들은 영화관에서 새로 개봉한 영화를 보고 근처 카페에서 시간을 보냈습니다.\",\n",
    "      \"ANSWER\": \"지호가 지난 주말에 친구들과 함께 한 활동은 영화 관람과 카페 방문입니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"미영이가 새로 산 가전제품은 무엇인가요?\",\n",
    "      \"CONTEXT\": \"미영이는 최근에 새로운 가전제품을 구입했습니다. 그녀는 오랫동안 원하던 로봇 청소기를 드디어 샀습니다.\",\n",
    "      \"ANSWER\": \"미영이가 새로 산 가전제품은 로봇 청소기입니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"준호가 다음 달에 갈 예정인 여행지는 어디인가요?\",\n",
    "      \"CONTEXT\": \"준호는 다음 달에 여행을 계획하고 있습니다. 그는 제주도에 가기로 했고, 이미 항공권과 숙소를 예약했습니다.\",\n",
    "      \"ANSWER\": \"준호가 다음 달에 갈 예정인 여행지는 제주도입니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"나영이가 매일 아침 하는 일은 무엇인가요?\",\n",
    "      \"CONTEXT\": \"나영이는 매일 아침 일찍 일어나서 조깅을 합니다. 조깅을 마친 후에는 집에서 간단한 스트레칭을 하고 아침 식사를 합니다.\",\n",
    "      \"ANSWER\": \"나영이가 매일 아침 하는 일은 조깅과 스트레칭입니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"민호가 직장에서 맡고 있는 업무는 무엇인가요?\",\n",
    "      \"CONTEXT\": \"민호는 IT 회사에서 근무하고 있습니다. 그는 주로 소프트웨어 개발과 관련된 업무를 맡고 있으며, 팀원들과 함께 프로젝트를 진행하고 있습니다.\",\n",
    "      \"ANSWER\": \"민호가 직장에서 맡고 있는 업무는 소프트웨어 개발입니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"수진이 다음 주에 참석할 예정인 행사는 무엇인가요?\",\n",
    "      \"CONTEXT\": \"수진이는 다음 주에 있을 회사 연말 파티에 참석할 예정입니다. 그녀는 파티를 위해 새 드레스를 구입했습니다.\",\n",
    "      \"ANSWER\": \"수진이 다음 주에 참석할 예정인 행사는 회사 연말 파티입니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"유진이 가장 좋아하는 계절은 무엇인가요?\",\n",
    "      \"CONTEXT\": \"유진이는 사계절 중에서 봄을 가장 좋아합니다. 그녀는 봄에 피는 꽃과 따뜻한 날씨를 즐기며, 주말마다 공원에 가는 것을 좋아합니다.\",\n",
    "      \"ANSWER\": \"유진이 가장 좋아하는 계절은 봄입니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"철수가 새로운 취미로 선택한 것은 무엇인가요?\",\n",
    "      \"CONTEXT\": \"철수는 새로운 취미로 요가를 선택했습니다. 그는 매주 요가 수업에 참석하며, 집에서도 꾸준히 연습하고 있습니다.\",\n",
    "      \"ANSWER\": \"철수가 새로운 취미로 선택한 것은 요가입니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"민정이 다니는 학교의 이름은 무엇인가요?\",\n",
    "      \"CONTEXT\": \"민정이는 서울에 있는 한양대학교에 다니고 있습니다. 그녀는 현재 2학년이며, 경영학을 전공하고 있습니다.\",\n",
    "      \"ANSWER\": \"민정이 다니는 학교의 이름은 한양대학교입니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"준영이가 좋아하는 운동은 무엇인가요?\",\n",
    "      \"CONTEXT\": \"준영이는 다양한 운동을 즐기지만, 특히 농구를 좋아합니다. 그는 매주 친구들과 농구 경기를 하며, 팀의 주전 선수로 활동하고 있습니다.\",\n",
    "      \"ANSWER\": \"준영이가 좋아하는 운동은 농구입니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"수아가 가장 최근에 읽은 책은 무엇인가요?\",\n",
    "      \"CONTEXT\": \"수아는 최근에 '해리 포터와 비밀의 방'을 읽었습니다. 이 책은 그녀가 가장 좋아하는 시리즈의 일부이며, 그녀는 매일 밤 이 책을 읽습니다.\",\n",
    "      \"ANSWER\": \"수아가 가장 최근에 읽은 책은 '해리 포터와 비밀의 방'입니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"지훈이 좋아하는 음악 장르는 무엇인가요?\",\n",
    "      \"CONTEXT\": \"지훈이는 다양한 음악 장르를 좋아하지만, 특히 클래식 음악을 즐겨 듣습니다. 그는 주로 피아노 연주곡을 좋아하며, 매일 아침 클래식 음악을 들으면서 하루를 시작합니다.\",\n",
    "      \"ANSWER\": \"지훈이 좋아하는 음악 장르는 클래식 음악입니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"나영이의 주말 계획은 무엇인가요?\",\n",
    "      \"CONTEXT\": \"나영이는 이번 주말에 가족과 함께 캠핑을 갈 계획입니다. 그녀는 캠핑 장비를 준비하고, 가족과 함께 자연 속에서 시간을 보낼 것입니다.\",\n",
    "      \"ANSWER\": \"나영이의 주말 계획은 가족과 함께 캠핑을 가는 것입니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"지수가 가장 최근에 본 영화는 무엇인가요?\",\n",
    "      \"CONTEXT\": \"지수는 최근에 영화 '어벤져스: 엔드게임'을 보았습니다. 이 영화는 그녀가 오랫동안 기다려 온 작품이며, 친구들과 함께 영화관에서 관람했습니다.\",\n",
    "      \"ANSWER\": \"지수가 가장 최근에 본 영화는 '어벤져스: 엔드게임'입니다.\"\n",
    "}\n",
    ",\n",
    "{\n",
    "      \"문제\": \"영희가 다음 주에 갈 여행지는 어디인가요?\",\n",
    "      \"CONTEXT\": \"영희는 다음 주에 제주도로 여행을 갈 계획입니다. 그녀는 이미 항공권과 숙소를 예약했으며, 여행 일정을 준비하고 있습니다.\",\n",
    "      \"ANSWER\": \"영희가 다음 주에 갈 여행지는 제주도입니다.\"\n",
    "}\n",
    "]\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(q).to_csv('./data/ko_추론문제.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\whdgh\\Desktop\\projects\\Langchain_Embedding\\.venv\\lib\\site-packages\\deepeval\\__init__.py:42: UserWarning: You are using deepeval version 0.21.47, however version 0.21.57 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n",
      "c:\\Users\\whdgh\\Desktop\\projects\\Langchain_Embedding\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\whdgh\\Desktop\\projects\\Langchain_Embedding\\.venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat ran up the tree."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The cat ran up the tree.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "import statistics\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = config['API']['OPENAI_API_KEY']\n",
    "\n",
    "from deepeval.metrics import *\n",
    "from deepeval.test_case import *\n",
    "\n",
    "from deepeval.benchmarks import *\n",
    "from deepeval.benchmarks.tasks import *\n",
    "\n",
    "from langchain_community.llms import GPT4All\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "input = \"The dog chased the cat up the tree, who ran up the tree?\"\n",
    "expected_output = \"cat.\"\n",
    "local_path = './models/nous-hermes-llama2-13b.Q4_0.gguf'\n",
    "\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    verbose=True,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    temperature=0.7,\n",
    ")\n",
    "llm_chain = (                     \n",
    "    PromptTemplate(input_variables=[\"question\"], template=input)\n",
    "    | model \n",
    "    | StrOutputParser()\n",
    ")\n",
    "actual_output = llm_chain.invoke({\"question\": \"\"})\n",
    "actual_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'input': 'Let x = 1. What is x << 3 in Python 3?\\nA. 1\\nB. 3\\nC. 8\\nD. 16\\nAnswer:',\n",
       "   'expected_output': 'C'},\n",
       "  {'input': 'In Python 3, which of the following function convert a string to an int in python?\\nA. int(x [,base])\\nB. long(x [,base] )\\nC. float(x)\\nD. str(x)\\nAnswer:',\n",
       "   'expected_output': 'A'},\n",
       "  {'input': \"A user enters a Web address in a browser, and a request for a file is sent to a Web server. Which of the following best describes how the file is sent to the user?\\nA. The file is broken into packets for transmission. The packets must be reassembled upon receipt.\\nB. The file is broken into packets for transmission. The user's browser must request each packet in order until all packets are received.\\nC. The server attempts to connect directly to the user's computer. If the connection is successful, the entire file is sent. If the connection is unsuccessful, an error message is sent to the user.\\nD. The server repeatedly attempts to connect directly to the user's computer until a connection is made. Once the connection is made, the entire file is sent.\\nAnswer:\",\n",
       "   'expected_output': 'A'}],\n",
       " 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmlu_benchmark = MMLU().load_benchmark_dataset(MMLUTask.HIGH_SCHOOL_COMPUTER_SCIENCE)\n",
    "data = [{'input': mmlu.input, 'expected_output': mmlu.expected_output} for mmlu in mmlu_benchmark]\n",
    "data[:3], len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = [\n",
    "    'APPLYING_SUNSCREEN',\n",
    "    'TRIMMING_BRANCHES_OR_HEDGES',\n",
    "    'DISC_DOG',\n",
    "    'WAKEBOARDING',\n",
    "    'SKATEBOARDING',\n",
    "    'WATERSKIING',\n",
    "    'WASHING_HANDS',\n",
    "    'SAILING',\n",
    "    'PLAYING_CONGAS',\n",
    "    'BALLET',\n",
    "    'ROOF_SHINGLE_REMOVAL',\n",
    "    'HAND_CAR_WASH',\n",
    "    'KITE_FLYING',\n",
    "    'PLAYING_POOL',\n",
    "    'PLAYING_LACROSSE',\n",
    "    'LAYUP_DRILL_IN_BASKETBALL',\n",
    "    'HOME_AND_GARDEN',\n",
    "    'PLAYING_BEACH_VOLLEYBALL',\n",
    "    'CALF_ROPING',\n",
    "    'SCUBA_DIVING',\n",
    "    'MIXING_DRINKS',\n",
    "    'PUTTING_ON_SHOES',\n",
    "    'MAKING_A_LEMONADE',\n",
    "    'UNCATEGORIZED',\n",
    "    'ZUMBA',\n",
    "    'PLAYING_BADMINTON',\n",
    "    'PLAYING_BAGPIPES',\n",
    "    'FOOD_AND_ENTERTAINING',\n",
    "    'PERSONAL_CARE_AND_STYLE',\n",
    "    'CRICKET',\n",
    "    'SHOVELING_SNOW',\n",
    "    'PING_PONG',\n",
    "    'HOLIDAYS_AND_TRADITIONS',\n",
    "    'ICE_FISHING',\n",
    "    'BEACH_SOCCER',\n",
    "    'TABLE_SOCCER',\n",
    "    'SWIMMING',\n",
    "    'BATON_TWIRLING',\n",
    "    'JAVELIN_THROW',\n",
    "    'SHOT_PUT',\n",
    "    'DOING_CRUNCHES',\n",
    "    'POLISHING_SHOES',\n",
    "    'TRAVEL',\n",
    "    'USING_UNEVEN_BARS',\n",
    "    'PLAYING_HARMONICA',\n",
    "    'RELATIONSHIPS',\n",
    "    'HIGH_JUMP',\n",
    "    'MAKING_A_SANDWICH',\n",
    "    'POWERBOCKING',\n",
    "    'REMOVING_ICE_FROM_CAR',\n",
    "    'SHAVING',\n",
    "    'SHARPENING_KNIVES',\n",
    "    'WELDING',\n",
    "    'USING_PARALLEL_BARS',\n",
    "    'HOME_CATEGORIES',\n",
    "    'ROCK_CLIMBING',\n",
    "    'SNOW_TUBING',\n",
    "    'WASHING_FACE',\n",
    "    'ASSEMBLING_BICYCLE',\n",
    "    'TENNIS_SERVE_WITH_BALL_BOUNCING',\n",
    "    'SHUFFLEBOARD',\n",
    "    'DODGEBALL',\n",
    "    'CAPOEIRA',\n",
    "    'PAINTBALL',\n",
    "    'DOING_A_POWERBOMB',\n",
    "    'DOING_MOTOCROSS',\n",
    "    'PLAYING_ICE_HOCKEY',\n",
    "    'PHILOSOPHY_AND_RELIGION',\n",
    "    'ARCHERY',\n",
    "    'CARS_AND_OTHER_VEHICLES',\n",
    "    'RUNNING_A_MARATHON',\n",
    "    'THROWING_DARTS',\n",
    "    'PAINTING_FURNITURE',\n",
    "    'HAVING_AN_ICE_CREAM',\n",
    "    'SLACKLINING',\n",
    "    'CAMEL_RIDE',\n",
    "    'ARM_WRESTLING',\n",
    "    'HULA_HOOP',\n",
    "    'SURFING',\n",
    "    'PLAYING_PIANO',\n",
    "    'GARGLING_MOUTHWASH',\n",
    "    'PLAYING_ACCORDION',\n",
    "    'HORSEBACK_RIDING',\n",
    "    'PUTTING_IN_CONTACT_LENSES',\n",
    "    'PLAYING_SAXOPHONE',\n",
    "    'FUTSAL',\n",
    "    'LONG_JUMP',\n",
    "    'LONGBOARDING',\n",
    "    'POLE_VAULT',\n",
    "    'BUILDING_SANDCASTLES',\n",
    "    'PLATFORM_DIVING',\n",
    "    'PAINTING',\n",
    "    'SPINNING',\n",
    "    'CARVING_JACK_O_LANTERNS',\n",
    "    'BRAIDING_HAIR',\n",
    "    'YOUTH',\n",
    "    'PLAYING_VIOLIN',\n",
    "    'CANOEING',\n",
    "    'CHEERLEADING',\n",
    "    'PETS_AND_ANIMALS',\n",
    "    'KAYAKING',\n",
    "    'CLEANING_SHOES',\n",
    "    'KNITTING',\n",
    "    'BAKING_COOKIES',\n",
    "    'DOING_FENCING',\n",
    "    'PLAYING_GUITARRA',\n",
    "    'USING_THE_ROWING_MACHINE',\n",
    "    'GETTING_A_HAIRCUT',\n",
    "    'MOOPING_FLOOR',\n",
    "    'RIVER_TUBING',\n",
    "    'CLEANING_SINK',\n",
    "    'GROOMING_DOG',\n",
    "    'DISCUS_THROW',\n",
    "    'CLEANING_WINDOWS',\n",
    "    'FINANCE_AND_BUSINESS',\n",
    "    'HANGING_WALLPAPER',\n",
    "    'ROPE_SKIPPING',\n",
    "    'WINDSURFING',\n",
    "    'KNEELING',\n",
    "    'GETTING_A_PIERCING',\n",
    "    'ROCK_PAPER_SCISSORS',\n",
    "    'SPORTS_AND_FITNESS',\n",
    "    'BREAKDANCING',\n",
    "    'WALKING_THE_DOG',\n",
    "    'PLAYING_DRUMS',\n",
    "    'PLAYING_WATER_POLO',\n",
    "    'BMX',\n",
    "    'SMOKING_A_CIGARETTE',\n",
    "    'BLOWING_LEAVES',\n",
    "    'BULLFIGHTING',\n",
    "    'DRINKING_COFFEE',\n",
    "    'BATHING_DOG',\n",
    "    'TANGO',\n",
    "    'WRAPPING_PRESENTS',\n",
    "    'PLASTERING',\n",
    "    'PLAYING_BLACKJACK',\n",
    "    'FUN_SLIDING_DOWN',\n",
    "    'WORK_WORLD',\n",
    "    'TRIPLE_JUMP',\n",
    "    'TUMBLING',\n",
    "    'SKIING',\n",
    "    'DOING_KICKBOXING',\n",
    "    'BLOW_DRYING_HAIR',\n",
    "    'DRUM_CORPS',\n",
    "    'SMOKING_HOOKAH',\n",
    "    'MOWING_THE_LAWN',\n",
    "    'VOLLEYBALL',\n",
    "    'LAYING_TILE',\n",
    "    'STARTING_A_CAMPFIRE',\n",
    "    'SUMO',\n",
    "    'HURLING',\n",
    "    'PLAYING_KICKBALL',\n",
    "    'MAKING_A_CAKE',\n",
    "    'FIXING_THE_ROOF',\n",
    "    'PLAYING_POLO',\n",
    "    'REMOVING_CURLERS',\n",
    "    'ELLIPTICAL_TRAINER',\n",
    "    'HEALTH',\n",
    "    'SPREAD_MULCH',\n",
    "    'CHOPPING_WOOD',\n",
    "    'BRUSHING_TEETH',\n",
    "    'USING_THE_POMMEL_HORSE',\n",
    "    'SNATCH',\n",
    "    'CLIPPING_CAT_CLAWS',\n",
    "    'PUTTING_ON_MAKEUP',\n",
    "    'HAND_WASHING_CLOTHES',\n",
    "    'HITTING_A_PINATA',\n",
    "    'TAI_CHI',\n",
    "    'GETTING_A_TATTOO',\n",
    "    'DRINKING_BEER',\n",
    "    'SHAVING_LEGS',\n",
    "    'DOING_KARATE',\n",
    "    'PLAYING_RUBIK_CUBE',\n",
    "    'FAMILY_LIFE',\n",
    "    'ROLLERBLADING',\n",
    "    'EDUCATION_AND_COMMUNICATIONS',\n",
    "    'FIXING_BICYCLE',\n",
    "    'BEER_PONG',\n",
    "    'IRONING_CLOTHES',\n",
    "    'CUTTING_THE_GRASS',\n",
    "    'RAKING_LEAVES',\n",
    "    'PLAYING_SQUASH',\n",
    "    'HOPSCOTCH',\n",
    "    'INSTALLING_CARPET',\n",
    "    'POLISHING_FURNITURE',\n",
    "    'DECORATING_THE_CHRISTMAS_TREE',\n",
    "    'PREPARING_SALAD',\n",
    "    'PREPARING_PASTA',\n",
    "    'VACUUMING_FLOOR',\n",
    "    'CLEAN_AND_JERK',\n",
    "    'COMPUTERS_AND_ELECTRONICS',\n",
    "    'CROQUET'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54218.35 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 50195.51 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55186.19 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55788.79 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 57056.78 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55481.98 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53989.28 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56734.91 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 57041.33 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54562.72 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53976.97 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55568.87 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54080.30 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56100.44 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54268.58 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 50963.39 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 51234.42 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53916.92 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55482.56 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54282.57 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55480.30 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 37894.36 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55461.16 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54887.02 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52031.20 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53416.19 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55775.05 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52852.68 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54581.53 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54681.09 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56736.05 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56508.08 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54000.08 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55590.94 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54875.43 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54037.01 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54801.61 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55107.27 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56114.49 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56114.34 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54936.85 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55775.94 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52078.48 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55327.26 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54901.11 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53688.27 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55481.32 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54575.66 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55775.35 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54047.27 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 47828.70 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 47379.51 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54266.48 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55480.74 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 50608.29 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56087.37 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54564.98 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53420.73 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53986.86 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 51721.89 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 38187.32 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55162.84 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54576.22 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54872.29 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52576.45 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53414.29 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55466.78 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52575.85 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55493.09 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52864.36 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55688.04 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55176.06 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55685.97 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53122.86 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54874.43 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55189.22 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55483.30 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56226.03 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54901.97 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54561.66 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55791.23 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56027.46 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56415.81 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55188.93 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55176.21 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 51969.95 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55475.62 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53608.19 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55085.86 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54293.13 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53977.11 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52853.48 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53712.78 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55795.74 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54604.38 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54576.65 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56100.29 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53853.57 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54874.22 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54275.15 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55493.90 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54470.42 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54265.50 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54575.30 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55175.92 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54576.37 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 51967.70 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55480.52 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 38038.82 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53148.33 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55176.06 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52031.32 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54591.08 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 51749.53 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53996.34 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 50208.73 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53245.69 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52196.46 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54292.43 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53427.98 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55161.90 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55169.63 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55486.58 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55467.44 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54955.27 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54280.82 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55802.17 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56085.72 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54280.47 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54281.52 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54575.94 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55163.27 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54575.80 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 49476.97 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54572.33 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54885.66 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53996.48 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54280.47 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55481.83 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55178.67 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55480.74 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55467.00 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54874.00 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52032.55 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55454.44 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56100.29 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53415.51 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56100.66 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 50945.63 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54267.46 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52289.84 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 51107.47 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 49467.32 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56416.87 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 50974.43 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 50477.22 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55163.42 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55776.09 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 36258.36 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54560.74 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54281.52 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53988.87 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 51219.34 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 53401.97 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52024.13 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 55082.33 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52760.06 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54280.54 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 41270.96 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54907.41 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54285.44 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52812.19 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54576.86 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54876.44 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54875.43 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 52853.48 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 50285.10 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54285.16 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54860.85 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54575.94 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 56101.26 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54576.15 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54281.31 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54575.73 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 54275.08 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 51292.32 examples/s]\n",
      "Filter: 100%|██████████| 10042/10042 [00:00<00:00, 50198.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_list = []\n",
    "for idx, b in enumerate(benchmarks):\n",
    "    data_list += HellaSwag().load_benchmark_dataset(HellaSwagTask[b])\n",
    "\n",
    "data = [{'input': obj.input, 'expected_output': obj.expected_output} for obj in data_list]\n",
    "pd.DataFrame(data).to_csv('HellaSwagData.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A. is using tools as he works."
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\whdgh\\Desktop\\projects\\Langchain_Embedding\\.venv\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\whdgh\\Desktop\\projects\\Langchain_Embedding\\.venv\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\whdgh\\Desktop\\projects\\Langchain_Embedding\\.venv\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\whdgh\\Desktop\\projects\\Langchain_Embedding\\.venv\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'metric_score': 1.0,\n",
       "  'metric_reason': 'The actual output directly indicates the correct expected output answer A, confirming he is using tools as he works.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = GEval(\n",
    "    name=\"Correctness\",\n",
    "    criteria=\"Determine whether the actual output is factually correct based on the expected output.\",\n",
    "    # NOTE: you can only provide either criteria or evaluation_steps, and not both\n",
    "    evaluation_steps=[\n",
    "        \"Check whether the facts in 'actual output' indicates the given 'expected output'\",\n",
    "        \"It does not matter whether the 'actual output' has full context or not.\",\n",
    "        \"If indicating to correct 'expected output' answer must be OK\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    ") \n",
    "\n",
    "benchmark = HumanEval(\n",
    "    tasks=[HumanEvalTask.HAS_CLOSE_ELEMENTS, HumanEvalTask.SORT_NUMBERS],\n",
    "    n=100\n",
    ")\n",
    "\n",
    "metric = HallucinationMetric(threshold=0.5)\n",
    "\n",
    "template = \"\"\"\n",
    "    You are a wise and precise chatbot.\n",
    "    With the below given questions, you will have to solve the question and answer the question instructed with several options to select\n",
    "    {question}\n",
    "    Provide only the letter corresponding to your answer (e.g., \"A\", \"B\", \"C\", etc.).\n",
    "\"\"\"\n",
    "\n",
    "llm_chain = (                     \n",
    "    PromptTemplate(input_variables=[\"question\"], template=template)\n",
    "    | model \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "test_result = []\n",
    "for evaluate in data:\n",
    "    # actual_output = llm_chain.invoke({\"question\": \"It depends, some might consider the cat, while others might argue the dog.\"})\n",
    "    actual_output = llm_chain.invoke({\"question\": evaluate['input']})\n",
    "    # actual_output = \"A\"\n",
    "\n",
    "    test_case = LLMTestCase(\n",
    "        input=evaluate['input'],\n",
    "        actual_output=actual_output,\n",
    "        expected_output=evaluate['expected_output']\n",
    "    )\n",
    "\n",
    "    metric.measure(test_case)\n",
    "    result = {'metric_score' : metric.score, 'metric_reason': metric.reason}\n",
    "    test_result.append(result)\n",
    "    break\n",
    "\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델: ChatOpenAI\n",
      "GEval 평가 평균: 1.0\n"
     ]
    }
   ],
   "source": [
    "len(test_result), test_result\n",
    "avg = statistics.mean([eval['metric_score'] for eval in test_result])\n",
    "print(f\"모델: ChatOpenAI\\nGEval 평가 평균: {avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_score</th>\n",
       "      <th>metric_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>The actual output directly indicates the corre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   metric_score                                      metric_reason\n",
       "0           1.0  The actual output directly indicates the corre..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(test_result).to_csv('result.csv', encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
